{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f32b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bef918",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.dbs.graphdb import GraphDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e533155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATABASE STATISTICS\n",
      "======================================================================\n",
      "\n",
      "Database: ../data/sqlite/graphdb.db\n",
      "Total Nodes: 16,362\n",
      "Total Edges: 55,607\n",
      "Total Embeddings: 5,047\n",
      "\n",
      "Nodes by Type:\n",
      "  affiliation         :    692\n",
      "  author              :  8,680\n",
      "  conference          :     20\n",
      "  domain              :  1,923\n",
      "  paper               :  5,047\n",
      "\n",
      "Edges by Relation Type:\n",
      "  author_in_affiliation         :  7,244\n",
      "  author_write_paper            : 14,096\n",
      "  paper_cite_paper              :  8,583\n",
      "  paper_in_domain               : 20,637\n",
      "  paper_in_venue                :  5,047\n"
     ]
    }
   ],
   "source": [
    "# Initialize database connection\n",
    "db = GraphDB(\n",
    "    db_path=\"../data/sqlite/graphdb.db\"\n",
    ")\n",
    "\n",
    "# Display database statistics\n",
    "print(\"=\" * 70)\n",
    "print(\"DATABASE STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "stats = db.stats()\n",
    "print(f\"\\nDatabase: {db.db_path}\")\n",
    "print(f\"Total Nodes: {stats['total_nodes']:,}\")\n",
    "print(f\"Total Edges: {stats['total_edges']:,}\")\n",
    "print(f\"Total Embeddings: {stats['total_embeddings']:,}\")\n",
    "\n",
    "print(f\"\\nNodes by Type:\")\n",
    "for node_type, count in sorted(stats['nodes_by_type'].items()):\n",
    "    print(f\"  {node_type:20s}: {count:6,}\")\n",
    "\n",
    "print(f\"\\nEdges by Relation Type:\")\n",
    "for rel_type, count in sorted(stats['edges_by_type'].items()):\n",
    "    print(f\"  {rel_type:30s}: {count:6,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f31c3a",
   "metadata": {},
   "source": [
    "## Demo 1: RAG (0-hop) - Vector Search Only\n",
    "\n",
    "Pure semantic search using vector embeddings. This is the foundation of RAG - retrieving relevant documents based on semantic similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5edacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RAG (0-hop): Vector Search\n",
      "======================================================================\n",
      "\n",
      "Query: 'machine learning'\n",
      "Retrieving top 3 papers...\n",
      "\n",
      "Results (3 papers, 367.77ms):\n",
      "----------------------------------------------------------------------\n",
      "1. Machine Learning by Function Decomposition\n",
      "   ID: 5A7BA6C1\n",
      "   Score: 0.6120\n",
      "\n",
      "2. Mechanism design via machine learning\n",
      "   ID: 7F4BED95\n",
      "   Score: 0.5755\n",
      "\n",
      "3. Detecting spam blogs: a machine learning approach\n",
      "   ID: 06518482\n",
      "   Score: 0.5334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def demo_rag(query: str, k: int = 3):\n",
    "    \"\"\"Demonstrate RAG: Vector search only.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"RAG (0-hop): Vector Search\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"Retrieving top {k} papers...\\n\")\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    results = db.search_by_text(query, k=k)\n",
    "    latency = (time.perf_counter() - start_time) * 1000\n",
    "    \n",
    "    print(f\"Results ({len(results)} papers, {latency:.2f}ms):\")\n",
    "    print(\"-\" * 70)\n",
    "    for i, paper in enumerate(results, 1):\n",
    "        print(f\"{i}. {paper['name']}\")\n",
    "        print(f\"   ID: {paper['id']}\")\n",
    "        print(f\"   Score: {paper['similarity']:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example queries\n",
    "query1 = \"machine learning\"\n",
    "results_rag = demo_rag(query1, k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cb51b9",
   "metadata": {},
   "source": [
    "## Demo 2: 1-Hop GraphRAG - Paper → Authors\n",
    "\n",
    "Extend RAG with graph traversal: find papers semantically, then traverse to their authors. This adds entity context to the retrieved documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70fc3e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "1-Hop GraphRAG: Paper → Authors\n",
      "======================================================================\n",
      "\n",
      "Query: 'information retrieval'\n",
      "Retrieving top 3 papers and their authors...\n",
      "\n",
      "Results (3 papers, 460.74ms):\n",
      "----------------------------------------------------------------------\n",
      "1. A case-based approach to intelligent information retrieval\n",
      "   ID: 7EA5DD49\n",
      "   Score: 0.6544\n",
      "   Authors (2):\n",
      "      • jody j daniels\n",
      "      • edwina l rissland\n",
      "\n",
      "2. Discriminative models for information retrieval\n",
      "   ID: 7B402A2B\n",
      "   Score: 0.5558\n",
      "   Authors (1):\n",
      "      • ramesh nallapati\n",
      "\n",
      "3. A hidden Markov model information retrieval system\n",
      "   ID: 7CE4C917\n",
      "   Score: 0.5547\n",
      "   Authors (3):\n",
      "      • tim leek\n",
      "      • david miller\n",
      "      • richard schwartz\n",
      "\n",
      "Summary: 3 papers, 6 total authors\n"
     ]
    }
   ],
   "source": [
    "def demo_1hop_graphrag(query: str, k: int = 3):\n",
    "    \"\"\"Demonstrate 1-hop GraphRAG: Papers → Authors.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"1-Hop GraphRAG: Paper → Authors\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"Retrieving top {k} papers and their authors...\\n\")\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # Vector search\n",
    "    papers = db.search_by_text(query, k=k)\n",
    "    \n",
    "    # Get authors for each paper\n",
    "    for paper in papers:\n",
    "        paper['authors'] = db.get_neighbors(\n",
    "            paper['id'],\n",
    "            direction='in',\n",
    "            relation_types=['author_write_paper']\n",
    "        )\n",
    "    \n",
    "    latency = (time.perf_counter() - start_time) * 1000\n",
    "    \n",
    "    print(f\"Results ({len(papers)} papers, {latency:.2f}ms):\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    total_authors = 0\n",
    "    for i, paper in enumerate(papers, 1):\n",
    "        print(f\"{i}. {paper['name']}\")\n",
    "        print(f\"   ID: {paper['id']}\")\n",
    "        print(f\"   Score: {paper['similarity']:.4f}\")\n",
    "        print(f\"   Authors ({len(paper['authors'])}):\")\n",
    "        for author in paper['authors']:\n",
    "            print(f\"      • {author['node_name']}\")\n",
    "        print()\n",
    "        total_authors += len(paper['authors'])\n",
    "    \n",
    "    print(f\"Summary: {len(papers)} papers, {total_authors} total authors\")\n",
    "    return papers\n",
    "\n",
    "# Example query\n",
    "query2 = \"information retrieval\"\n",
    "results_1hop = demo_1hop_graphrag(query2, k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdb75e8",
   "metadata": {},
   "source": [
    "## Demo 3: 2-Hop GraphRAG - Paper → Authors → Affiliations\n",
    "\n",
    "Multi-hop traversal: find papers, traverse to authors, then to their affiliations. This demonstrates how graph structure enriches retrieval with institutional context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c7be938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "2-Hop GraphRAG: Paper → Authors → Affiliations\n",
      "======================================================================\n",
      "\n",
      "Query: 'deep learning'\n",
      "Retrieving top 3 papers, authors, and affiliations...\n",
      "\n",
      "Results (3 papers, 352.98ms):\n",
      "----------------------------------------------------------------------\n",
      "1. Deep learning via semi-supervised embedding\n",
      "   ID: 80B42CFC\n",
      "   Score: 0.6169\n",
      "   Authors (3):\n",
      "      • jason weston\n",
      "        Affiliations (2):\n",
      "          → royal holloway university of london\n",
      "          → nec\n",
      "      • ronan collobert\n",
      "        Affiliations (1):\n",
      "          → nec\n",
      "      • frederic ratle\n",
      "        Affiliations (1):\n",
      "          → university of lausanne\n",
      "\n",
      "2. Deep learning via Hessian-free optimization\n",
      "   ID: 0BBA56E8\n",
      "   Score: 0.5752\n",
      "   Authors (1):\n",
      "      • james martens\n",
      "        Affiliations (1):\n",
      "          → university of toronto\n",
      "\n",
      "3. A unified architecture for natural language processing: deep neural networks with multitask learning\n",
      "   ID: 7E30D880\n",
      "   Score: 0.5320\n",
      "   Authors (2):\n",
      "      • jason weston\n",
      "        Affiliations (2):\n",
      "          → max planck society\n",
      "          → nec\n",
      "      • ronan collobert\n",
      "        Affiliations (1):\n",
      "          → nec\n",
      "\n",
      "Summary: 3 papers, 6 authors, 8 affiliations\n"
     ]
    }
   ],
   "source": [
    "def demo_2hop_graphrag(query: str, k: int = 3):\n",
    "    \"\"\"Demonstrate 2-hop GraphRAG: Papers → Authors → Affiliations.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"2-Hop GraphRAG: Paper → Authors → Affiliations\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"Retrieving top {k} papers, authors, and affiliations...\\n\")\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # Vector search\n",
    "    papers = db.search_by_text(query, k=k)\n",
    "    \n",
    "    # Get authors for each paper\n",
    "    for paper in papers:\n",
    "        paper['authors'] = db.get_neighbors(\n",
    "            paper['id'],\n",
    "            direction='in',\n",
    "            relation_types=['author_write_paper']\n",
    "        )\n",
    "        \n",
    "        # Get affiliations for each author\n",
    "        for author in paper['authors']:\n",
    "            author['affiliations'] = db.get_neighbors(\n",
    "                author['node_id'],\n",
    "                direction='out',\n",
    "                relation_types=['author_in_affiliation']\n",
    "            )\n",
    "    \n",
    "    latency = (time.perf_counter() - start_time) * 1000\n",
    "    \n",
    "    print(f\"Results ({len(papers)} papers, {latency:.2f}ms):\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    total_authors = 0\n",
    "    total_affs = 0\n",
    "    for i, paper in enumerate(papers, 1):\n",
    "        print(f\"{i}. {paper['name']}\")\n",
    "        print(f\"   ID: {paper['id']}\")\n",
    "        print(f\"   Score: {paper['similarity']:.4f}\")\n",
    "        print(f\"   Authors ({len(paper['authors'])}):\")\n",
    "        \n",
    "        for author in paper['authors']:\n",
    "            print(f\"      • {author['node_name']}\")\n",
    "            if author['affiliations']:\n",
    "                print(f\"        Affiliations ({len(author['affiliations'])}):\")\n",
    "                for aff in author['affiliations']:\n",
    "                    print(f\"          → {aff['node_name']}\")\n",
    "            else:\n",
    "                print(f\"        → No affiliation\")\n",
    "            total_affs += len(author['affiliations'])\n",
    "        \n",
    "        total_authors += len(paper['authors'])\n",
    "        print()\n",
    "    \n",
    "    print(f\"Summary: {len(papers)} papers, {total_authors} authors, {total_affs} affiliations\")\n",
    "    return papers\n",
    "\n",
    "# Example query\n",
    "query3 = \"deep learning\"\n",
    "results_2hop = demo_2hop_graphrag(query3, k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18c255",
   "metadata": {},
   "source": [
    "## Demo 4: Inverse Traversal - Paper → Author → Co-authored Papers\n",
    "\n",
    "Bidirectional graph traversal: find papers, get authors, then find other papers by those authors. This demonstrates discovering related papers through shared authorship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa1428b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Inverse Traversal: Paper → Author → Co-authored Papers\n",
      "======================================================================\n",
      "\n",
      "Query: 'neural networks'\n",
      "Finding papers, then discovering co-authored papers...\n",
      "\n",
      "Results (2 seed papers, 295.52ms):\n",
      "----------------------------------------------------------------------\n",
      "1. Seed Paper: How to Train Neural Networks\n",
      "   ID: 5E72175B\n",
      "   Authors (2):\n",
      "      • hansgeorg zimmermann\n",
      "        → No other papers found\n",
      "      • ralph neuneier\n",
      "        Co-authored Papers (2):\n",
      "          → Risk sensitive reinforcement learning\n",
      "          → Optimal Asset Allocation using Adaptive Dynamic Programming\n",
      "\n",
      "2. Seed Paper: Intrusion detection with neural networks\n",
      "   ID: 7FEC5C75\n",
      "   Authors (3):\n",
      "      • j p ryan\n",
      "        → No other papers found\n",
      "      • mengjang lin\n",
      "        → No other papers found\n",
      "      • risto miikkulainen\n",
      "        Co-authored Papers (2):\n",
      "          → Forming neural networks through efficient and adaptive coevolution\n",
      "          → SARDNET: A Self-Organizing Feature Map for Sequences\n",
      "\n",
      "Summary: 2 seed papers, 5 authors, 4 related papers discovered\n"
     ]
    }
   ],
   "source": [
    "def demo_inverse_traversal(query: str, k: int = 2):\n",
    "    \"\"\"Demonstrate inverse traversal: Paper → Author → Other Papers.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Inverse Traversal: Paper → Author → Co-authored Papers\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"Finding papers, then discovering co-authored papers...\\n\")\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # Vector search\n",
    "    papers = db.search_by_text(query, k=k)\n",
    "    \n",
    "    # Get authors for each paper\n",
    "    for paper in papers:\n",
    "        paper['authors'] = db.get_neighbors(\n",
    "            paper['id'],\n",
    "            direction='in',\n",
    "            relation_types=['author_write_paper']\n",
    "        )\n",
    "        \n",
    "        # Get other papers by each author\n",
    "        for author in paper['authors']:\n",
    "            author['other_papers'] = db.get_neighbors(\n",
    "                author['node_id'],\n",
    "                direction='out',\n",
    "                relation_types=['author_write_paper']\n",
    "            )\n",
    "            # Filter out the seed paper itself\n",
    "            author['other_papers'] = [\n",
    "                p for p in author['other_papers'] \n",
    "                if p['node_id'] != paper['id']\n",
    "            ]\n",
    "    \n",
    "    latency = (time.perf_counter() - start_time) * 1000\n",
    "    \n",
    "    print(f\"Results ({len(papers)} seed papers, {latency:.2f}ms):\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    total_authors = 0\n",
    "    total_related_papers = 0\n",
    "    for i, paper in enumerate(papers, 1):\n",
    "        print(f\"{i}. Seed Paper: {paper['name']}\")\n",
    "        print(f\"   ID: {paper['id']}\")\n",
    "        print(f\"   Authors ({len(paper['authors'])}):\")\n",
    "        \n",
    "        for author in paper['authors']:\n",
    "            print(f\"      • {author['node_name']}\")\n",
    "            if author['other_papers']:\n",
    "                print(f\"        Co-authored Papers ({len(author['other_papers'])}):\")\n",
    "                for other_paper in author['other_papers'][:5]:  # Show max 5\n",
    "                    print(f\"          → {other_paper['node_name']}\")\n",
    "                if len(author['other_papers']) > 5:\n",
    "                    print(f\"          ... and {len(author['other_papers']) - 5} more\")\n",
    "            else:\n",
    "                print(f\"        → No other papers found\")\n",
    "            total_related_papers += len(author['other_papers'])\n",
    "        \n",
    "        total_authors += len(paper['authors'])\n",
    "        print()\n",
    "    \n",
    "    print(f\"Summary: {len(papers)} seed papers, {total_authors} authors, {total_related_papers} related papers discovered\")\n",
    "    return papers\n",
    "\n",
    "# Example query\n",
    "query4 = \"neural networks\"\n",
    "results_inverse = demo_inverse_traversal(query4, k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed8a8d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Clean up: close database connection\n",
    "db.close()\n",
    "print(\"Database connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba2d874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
